{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "3689760c-41f8-4a33-9c96-3fd17803950e",
        "_uuid": "3e0ad409d438c7c68ea6a76700a1e964a357453f",
        "id": "8GkmjpNRwLSY"
      },
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\"> Credit Fraud Detector </h1>\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "fTW76-8PwLSZ"
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in\n",
        "\n",
        "# Imported Libraries\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "import matplotlib.patches as mpatches\n",
        "import time\n",
        "\n",
        "# Classifier Libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import collections\n",
        "\n",
        "\n",
        "# Other Libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "df = pd.read_csv('../input/creditcard.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "376ce881-463a-4a09-9ac0-c63f85577eec",
        "_uuid": "93031e732e5aca3a2b4984799d6bf58d76e4b52d",
        "trusted": true,
        "id": "89SDvQTMwLSZ"
      },
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "03ddb929-5bc8-4af4-90cd-21dcbb57560d",
        "_uuid": "38bec67888aa534e9739e95ef9fac62d27a87021",
        "trusted": true,
        "id": "yLyWHM9IwLSZ"
      },
      "cell_type": "code",
      "source": [
        "# Good No Null Values!\n",
        "df.isnull().sum().max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "6a526b6c-8463-4f6f-92b0-e8a3a21cbb2e",
        "_uuid": "479a5f12d3dd68262316a17b4b7b3499e0a2cbe0",
        "trusted": true,
        "id": "bwgm0iyUwLSZ"
      },
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "01c007fa-0fcc-4eea-84ff-0861a2f8c533",
        "_uuid": "f6b96ff34855e3bf7af1f6979342b01c473e4e07",
        "trusted": true,
        "id": "GsoPzjZowLSZ"
      },
      "cell_type": "code",
      "source": [
        "# The classes are heavily skewed we need to solve this issue later.\n",
        "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
        "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "657bc987-4b15-4cfa-b290-c39a2632e2ac",
        "_uuid": "337caaf6ed3f65beedb24a74eebb22d97ff52ba4",
        "trusted": true,
        "id": "PXQrgwdkwLSa"
      },
      "cell_type": "code",
      "source": [
        "colors = [\"#0101DF\", \"#DF0101\"]\n",
        "\n",
        "sns.countplot('Class', data=df, palette=colors)\n",
        "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "cee315f2-325f-42b6-a640-736f10c272cc",
        "_uuid": "cfa51792bf6f8a6b318ae1bffcff4e922b1d1917",
        "trusted": true,
        "id": "_-CZqBsZwLSa"
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(18,4))\n",
        "\n",
        "amount_val = df['Amount'].values\n",
        "time_val = df['Time'].values\n",
        "\n",
        "sns.distplot(amount_val, ax=ax[0], color='r')\n",
        "ax[0].set_title('Distribution of Transaction Amount', fontsize=14)\n",
        "ax[0].set_xlim([min(amount_val), max(amount_val)])\n",
        "\n",
        "sns.distplot(time_val, ax=ax[1], color='b')\n",
        "ax[1].set_title('Distribution of Transaction Time', fontsize=14)\n",
        "ax[1].set_xlim([min(time_val), max(time_val)])\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "d5d64bf0-2fbb-4096-a265-f68887bf2fde",
        "_uuid": "1501ec379c9b5c39c3857ba0febd0aedee9c30d5",
        "trusted": true,
        "id": "HGC-ulCcwLSa"
      },
      "cell_type": "code",
      "source": [
        "# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "\n",
        "# RobustScaler is less prone to outliers.\n",
        "\n",
        "std_scaler = StandardScaler()\n",
        "rob_scaler = RobustScaler()\n",
        "\n",
        "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
        "\n",
        "df.drop(['Time','Amount'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "cdb9bb1e-9fab-4fd1-a409-468ba8bc36ee",
        "_uuid": "a33d701247ab45d849c5e94735346a738a6c6970",
        "trusted": true,
        "id": "sOZQjWKxwLSa"
      },
      "cell_type": "code",
      "source": [
        "scaled_amount = df['scaled_amount']\n",
        "scaled_time = df['scaled_time']\n",
        "\n",
        "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
        "df.insert(0, 'scaled_amount', scaled_amount)\n",
        "df.insert(1, 'scaled_time', scaled_time)\n",
        "\n",
        "# Amount and Time are Scaled!\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "c6c962cc-6f38-4a00-bcd7-ce9d91db954c",
        "_uuid": "9f7b5d920703b3a3c8c0f62bc6042e4615bc8324",
        "trusted": true,
        "id": "nJjKfvGUwLSa"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
        "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')\n",
        "\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
        "\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
        "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
        "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "# We already have X_train and y_train for undersample data thats why I am using original to distinguish and to not overwrite these variables.\n",
        "# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the Distribution of the labels\n",
        "\n",
        "\n",
        "# Turn into an array\n",
        "original_Xtrain = original_Xtrain.values\n",
        "original_Xtest = original_Xtest.values\n",
        "original_ytrain = original_ytrain.values\n",
        "original_ytest = original_ytest.values\n",
        "\n",
        "# See if both the train and test label distribution are similarly distributed\n",
        "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
        "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
        "print('-' * 100)\n",
        "\n",
        "print('Label Distributions: \\n')\n",
        "print(train_counts_label/ len(original_ytrain))\n",
        "print(test_counts_label/ len(original_ytest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "f0acfc44-eb2a-4356-ad03-d0c12807acd7",
        "_uuid": "e3a2b89752681164f14c8273452fc66734d7f41b",
        "trusted": true,
        "id": "b-YRgqJcwLSb"
      },
      "cell_type": "code",
      "source": [
        "# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
        "\n",
        "# Lets shuffle the data before creating the subsamples\n",
        "\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "# amount of fraud classes 492 rows.\n",
        "fraud_df = df.loc[df['Class'] == 1]\n",
        "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
        "\n",
        "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
        "\n",
        "# Shuffle dataframe rows\n",
        "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
        "\n",
        "new_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "77198464-c0f8-4694-ac0b-4b29b94d0da3",
        "_uuid": "b6818122806657e7accb8be1f4bf17086bb9b149",
        "id": "-5Rk8XP_wLSb"
      },
      "cell_type": "markdown",
      "source": [
        "##  Equally Distributing and Correlating:\n"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "73454100-dc69-49fd-b1b2-f72e326bca5d",
        "_uuid": "68b42e92df59f10fbd3ba700389796c4506af604",
        "trusted": true,
        "id": "nbYSCMdgwLSb"
      },
      "cell_type": "code",
      "source": [
        "print('Distribution of the Classes in the subsample dataset')\n",
        "print(new_df['Class'].value_counts()/len(new_df))\n",
        "\n",
        "\n",
        "\n",
        "sns.countplot('Class', data=new_df, palette=colors)\n",
        "plt.title('Equally Distributed Classes', fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0abc31ee-a78e-43af-822f-f06772d00c1c",
        "_uuid": "88477bac6687f110e9d64ec22837c250d85d2a2b",
        "id": "B5rAi6A2wLSb"
      },
      "cell_type": "markdown",
      "source": [
        "<h3> Correlation Matrices </h3>\n"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "9f353623-9435-4bb2-b854-b4a201ec7dd9",
        "_uuid": "e2f417c5d7c633a1e3cdfaa78acd6bd77a38400e",
        "trusted": true,
        "id": "oNyb_uFQwLSb"
      },
      "cell_type": "code",
      "source": [
        "# Make sure we use the subsample in our correlation\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,20))\n",
        "\n",
        "# Entire DataFrame\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax1)\n",
        "ax1.set_title(\"Imbalanced Correlation Matrix \\n (don't use for reference)\", fontsize=14)\n",
        "\n",
        "\n",
        "sub_sample_corr = new_df.corr()\n",
        "sns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax2)\n",
        "ax2.set_title('SubSample Correlation Matrix \\n (use for reference)', fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "2f02c21f-daa3-4251-a8e9-acad09a5ce0f",
        "_uuid": "318d0e7e0443f99139be21c00a7abc663be26385",
        "trusted": true,
        "id": "QZDrpiuTwLSb"
      },
      "cell_type": "code",
      "source": [
        "f, axes = plt.subplots(ncols=4, figsize=(20,4))\n",
        "\n",
        "# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\n",
        "sns.boxplot(x=\"Class\", y=\"V17\", data=new_df, palette=colors, ax=axes[0])\n",
        "axes[0].set_title('V17 vs Class Negative Correlation')\n",
        "\n",
        "sns.boxplot(x=\"Class\", y=\"V14\", data=new_df, palette=colors, ax=axes[1])\n",
        "axes[1].set_title('V14 vs Class Negative Correlation')\n",
        "\n",
        "\n",
        "sns.boxplot(x=\"Class\", y=\"V12\", data=new_df, palette=colors, ax=axes[2])\n",
        "axes[2].set_title('V12 vs Class Negative Correlation')\n",
        "\n",
        "\n",
        "sns.boxplot(x=\"Class\", y=\"V10\", data=new_df, palette=colors, ax=axes[3])\n",
        "axes[3].set_title('V10 vs Class Negative Correlation')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "b457b10e-c17c-4cb2-9719-6d4128377c9f",
        "_uuid": "7bfc46c028f8602ee949de83629082633aa47b2c",
        "trusted": true,
        "id": "YTGlLbeTwLSb"
      },
      "cell_type": "code",
      "source": [
        "f, axes = plt.subplots(ncols=4, figsize=(20,4))\n",
        "\n",
        "# Positive correlations (The higher the feature the probability increases that it will be a fraud transaction)\n",
        "sns.boxplot(x=\"Class\", y=\"V11\", data=new_df, palette=colors, ax=axes[0])\n",
        "axes[0].set_title('V11 vs Class Positive Correlation')\n",
        "\n",
        "sns.boxplot(x=\"Class\", y=\"V4\", data=new_df, palette=colors, ax=axes[1])\n",
        "axes[1].set_title('V4 vs Class Positive Correlation')\n",
        "\n",
        "\n",
        "sns.boxplot(x=\"Class\", y=\"V2\", data=new_df, palette=colors, ax=axes[2])\n",
        "axes[2].set_title('V2 vs Class Positive Correlation')\n",
        "\n",
        "\n",
        "sns.boxplot(x=\"Class\", y=\"V19\", data=new_df, palette=colors, ax=axes[3])\n",
        "axes[3].set_title('V19 vs Class Positive Correlation')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "93e56c89-185e-40d2-9ccc-29b123feb5a6",
        "_uuid": "a721282c0f44ec8030bbad6d0220091bde8cbec8",
        "id": "H38p-MFrwLSb"
      },
      "cell_type": "markdown",
      "source": [
        "## Anomaly Detection:\n"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "9c690dfa-8fed-44e5-99f5-ff4eb6f87f16",
        "_uuid": "b6963900379db5b0d4adf92f8c7f959164e9119f",
        "trusted": true,
        "id": "l1DrcgiAwLSb"
      },
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "f, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20, 6))\n",
        "\n",
        "v14_fraud_dist = new_df['V14'].loc[new_df['Class'] == 1].values\n",
        "sns.distplot(v14_fraud_dist,ax=ax1, fit=norm, color='#FB8861')\n",
        "ax1.set_title('V14 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "v12_fraud_dist = new_df['V12'].loc[new_df['Class'] == 1].values\n",
        "sns.distplot(v12_fraud_dist,ax=ax2, fit=norm, color='#56F9BB')\n",
        "ax2.set_title('V12 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "\n",
        "v10_fraud_dist = new_df['V10'].loc[new_df['Class'] == 1].values\n",
        "sns.distplot(v10_fraud_dist,ax=ax3, fit=norm, color='#C5B3F9')\n",
        "ax3.set_title('V10 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "2e19fe33-f85a-4ffd-8e4a-807d0e0fb992",
        "_uuid": "21e43406e62a9561fba2f065ce15a8d87a1bf389",
        "trusted": true,
        "id": "SZYtlh4FwLSb"
      },
      "cell_type": "code",
      "source": [
        "# # -----> V14 Removing Outliers (Highest Negative Correlated with Labels)\n",
        "v14_fraud = new_df['V14'].loc[new_df['Class'] == 1].values\n",
        "q25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)\n",
        "print('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\n",
        "v14_iqr = q75 - q25\n",
        "print('iqr: {}'.format(v14_iqr))\n",
        "\n",
        "v14_cut_off = v14_iqr * 1.5\n",
        "v14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off\n",
        "print('Cut Off: {}'.format(v14_cut_off))\n",
        "print('V14 Lower: {}'.format(v14_lower))\n",
        "print('V14 Upper: {}'.format(v14_upper))\n",
        "\n",
        "outliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]\n",
        "print('Feature V14 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
        "print('V10 outliers:{}'.format(outliers))\n",
        "\n",
        "new_df = new_df.drop(new_df[(new_df['V14'] > v14_upper) | (new_df['V14'] < v14_lower)].index)\n",
        "print('----' * 44)\n",
        "\n",
        "# -----> V12 removing outliers from fraud transactions\n",
        "v12_fraud = new_df['V12'].loc[new_df['Class'] == 1].values\n",
        "q25, q75 = np.percentile(v12_fraud, 25), np.percentile(v12_fraud, 75)\n",
        "v12_iqr = q75 - q25\n",
        "\n",
        "v12_cut_off = v12_iqr * 1.5\n",
        "v12_lower, v12_upper = q25 - v12_cut_off, q75 + v12_cut_off\n",
        "print('V12 Lower: {}'.format(v12_lower))\n",
        "print('V12 Upper: {}'.format(v12_upper))\n",
        "outliers = [x for x in v12_fraud if x < v12_lower or x > v12_upper]\n",
        "print('V12 outliers: {}'.format(outliers))\n",
        "print('Feature V12 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
        "new_df = new_df.drop(new_df[(new_df['V12'] > v12_upper) | (new_df['V12'] < v12_lower)].index)\n",
        "print('Number of Instances after outliers removal: {}'.format(len(new_df)))\n",
        "print('----' * 44)\n",
        "\n",
        "\n",
        "# Removing outliers V10 Feature\n",
        "v10_fraud = new_df['V10'].loc[new_df['Class'] == 1].values\n",
        "q25, q75 = np.percentile(v10_fraud, 25), np.percentile(v10_fraud, 75)\n",
        "v10_iqr = q75 - q25\n",
        "\n",
        "v10_cut_off = v10_iqr * 1.5\n",
        "v10_lower, v10_upper = q25 - v10_cut_off, q75 + v10_cut_off\n",
        "print('V10 Lower: {}'.format(v10_lower))\n",
        "print('V10 Upper: {}'.format(v10_upper))\n",
        "outliers = [x for x in v10_fraud if x < v10_lower or x > v10_upper]\n",
        "print('V10 outliers: {}'.format(outliers))\n",
        "print('Feature V10 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
        "new_df = new_df.drop(new_df[(new_df['V10'] > v10_upper) | (new_df['V10'] < v10_lower)].index)\n",
        "print('Number of Instances after outliers removal: {}'.format(len(new_df)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "66e44398-7c91-4cce-9778-4512cb838973",
        "_uuid": "ac80d9cfb07f1865094a8d460ae801750e93d694",
        "trusted": true,
        "id": "IWrqVobvwLSc"
      },
      "cell_type": "code",
      "source": [
        "f,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,6))\n",
        "\n",
        "colors = ['#B3F9C5', '#f9c5b3']\n",
        "# Boxplots with outliers removed\n",
        "# Feature V14\n",
        "sns.boxplot(x=\"Class\", y=\"V14\", data=new_df,ax=ax1, palette=colors)\n",
        "ax1.set_title(\"V14 Feature \\n Reduction of outliers\", fontsize=14)\n",
        "ax1.annotate('Fewer extreme \\n outliers', xy=(0.98, -17.5), xytext=(0, -12),\n",
        "            arrowprops=dict(facecolor='black'),\n",
        "            fontsize=14)\n",
        "\n",
        "# Feature 12\n",
        "sns.boxplot(x=\"Class\", y=\"V12\", data=new_df, ax=ax2, palette=colors)\n",
        "ax2.set_title(\"V12 Feature \\n Reduction of outliers\", fontsize=14)\n",
        "ax2.annotate('Fewer extreme \\n outliers', xy=(0.98, -17.3), xytext=(0, -12),\n",
        "            arrowprops=dict(facecolor='black'),\n",
        "            fontsize=14)\n",
        "\n",
        "# Feature V10\n",
        "sns.boxplot(x=\"Class\", y=\"V10\", data=new_df, ax=ax3, palette=colors)\n",
        "ax3.set_title(\"V10 Feature \\n Reduction of outliers\", fontsize=14)\n",
        "ax3.annotate('Fewer extreme \\n outliers', xy=(0.95, -16.5), xytext=(0, -12),\n",
        "            arrowprops=dict(facecolor='black'),\n",
        "            fontsize=14)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "74903f3b-dc6b-40ba-abc8-86c3df5ca46e",
        "_uuid": "0b365b10bd363c23068accc448509ced879f1670",
        "id": "4me7-PwywLSc"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Dimensionality Reduction and Clustering: </h2>\n"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "f83cde6b-90d0-4e9d-ac63-fb69780431b2",
        "_uuid": "af3027e7df67b75c92c88d597003632e285c9bff",
        "trusted": true,
        "id": "u_YsMl8xwLSc"
      },
      "cell_type": "code",
      "source": [
        "# New_df is from the random undersample data (fewer instances)\n",
        "X = new_df.drop('Class', axis=1)\n",
        "y = new_df['Class']\n",
        "\n",
        "\n",
        "# T-SNE Implementation\n",
        "t0 = time.time()\n",
        "X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(X.values)\n",
        "t1 = time.time()\n",
        "print(\"T-SNE took {:.2} s\".format(t1 - t0))\n",
        "\n",
        "# PCA Implementation\n",
        "t0 = time.time()\n",
        "X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(X.values)\n",
        "t1 = time.time()\n",
        "print(\"PCA took {:.2} s\".format(t1 - t0))\n",
        "\n",
        "# TruncatedSVD\n",
        "t0 = time.time()\n",
        "X_reduced_svd = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42).fit_transform(X.values)\n",
        "t1 = time.time()\n",
        "print(\"Truncated SVD took {:.2} s\".format(t1 - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "07015ae5-f7ac-4d64-8f41-1e4b7c9dd2ac",
        "_uuid": "084f2a7421c2212082491d2a90e65d65c52b434a",
        "trusted": true,
        "id": "LkGVqEfYwLSc"
      },
      "cell_type": "code",
      "source": [
        "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24,6))\n",
        "# labels = ['No Fraud', 'Fraud']\n",
        "f.suptitle('Clusters using Dimensionality Reduction', fontsize=14)\n",
        "\n",
        "\n",
        "blue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\n",
        "red_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n",
        "\n",
        "\n",
        "# t-SNE scatter plot\n",
        "ax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
        "ax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
        "ax1.set_title('t-SNE', fontsize=14)\n",
        "\n",
        "ax1.grid(True)\n",
        "\n",
        "ax1.legend(handles=[blue_patch, red_patch])\n",
        "\n",
        "\n",
        "# PCA scatter plot\n",
        "ax2.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
        "ax2.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
        "ax2.set_title('PCA', fontsize=14)\n",
        "\n",
        "ax2.grid(True)\n",
        "\n",
        "ax2.legend(handles=[blue_patch, red_patch])\n",
        "\n",
        "# TruncatedSVD scatter plot\n",
        "ax3.scatter(X_reduced_svd[:,0], X_reduced_svd[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
        "ax3.scatter(X_reduced_svd[:,0], X_reduced_svd[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
        "ax3.set_title('Truncated SVD', fontsize=14)\n",
        "\n",
        "ax3.grid(True)\n",
        "\n",
        "ax3.legend(handles=[blue_patch, red_patch])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "cb2c480a-090a-4cfb-b12e-3b74c325826c",
        "_uuid": "1b63bfd92008043cc1a336f924c835e73792f6d8",
        "id": "rcHsVc0bwLSc"
      },
      "cell_type": "markdown",
      "source": [
        "<h2> Classifiers (UnderSampling):  </h2>\n"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "85ce8738-7599-4b06-a722-5c0ed073599b",
        "_uuid": "e3751d88766a982119e522e27a9c0c647f20af85",
        "trusted": true,
        "id": "5s_g2kvfwLSc"
      },
      "cell_type": "code",
      "source": [
        "# Undersampling before cross validating (prone to overfit)\n",
        "X = new_df.drop('Class', axis=1)\n",
        "y = new_df['Class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "288a65b7-8b86-44b1-973d-38dbcfe82bbb",
        "_uuid": "fb0a479efaa7147d6702c2c24083f1118621863f",
        "trusted": true,
        "id": "C4N1Q5xtwLSc"
      },
      "cell_type": "code",
      "source": [
        "# Our data is already scaled we should split our training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# This is explicitly used for undersampling.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "bccd5685-a979-451e-85b3-1cb968523540",
        "_uuid": "28f5178089d2d133b9e7478c1c7dc7a1f98aabee",
        "trusted": true,
        "id": "O17boW3FwLSc"
      },
      "cell_type": "code",
      "source": [
        "# Turn the values into an array for feeding the classification algorithms.\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_train = y_train.values\n",
        "y_test = y_test.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "7810d0b9-b4e5-4b7f-909b-c127365b167c",
        "_uuid": "8dd4ea07fd60973fccabc2d46af28a09b0de9178",
        "trusted": true,
        "id": "9t9NgiYqwLSc"
      },
      "cell_type": "code",
      "source": [
        "# Let's implement simple classifiers\n",
        "\n",
        "classifiers = {\n",
        "    \"LogisiticRegression\": LogisticRegression(),\n",
        "    \"KNearest\": KNeighborsClassifier(),\n",
        "    \"Support Vector Classifier\": SVC(),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "eb37c0f6-9cfe-48b6-92d3-475d5e6767a6",
        "_uuid": "fe129af379caccc5428cf1836e6c96bd32e68feb",
        "trusted": true,
        "id": "eJVkFlplwLSc"
      },
      "cell_type": "code",
      "source": [
        "# Wow our scores are getting even high scores even when applying cross validation.\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "for key, classifier in classifiers.items():\n",
        "    classifier.fit(X_train, y_train)\n",
        "    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n",
        "    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "a1c35773-f4c7-4caf-9911-532784c9eae0",
        "_uuid": "d15b1ab16737358806e34c48dc57aa238cf0cfd2",
        "trusted": true,
        "id": "hWHahrmtwLSc"
      },
      "cell_type": "code",
      "source": [
        "# Use GridSearchCV to find the best parameters.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Logistic Regression\n",
        "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "\n",
        "\n",
        "grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\n",
        "grid_log_reg.fit(X_train, y_train)\n",
        "# We automatically get the logistic regression with the best parameters.\n",
        "log_reg = grid_log_reg.best_estimator_\n",
        "\n",
        "knears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
        "\n",
        "grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\n",
        "grid_knears.fit(X_train, y_train)\n",
        "# KNears best estimator\n",
        "knears_neighbors = grid_knears.best_estimator_\n",
        "\n",
        "# Support Vector Classifier\n",
        "svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n",
        "grid_svc = GridSearchCV(SVC(), svc_params)\n",
        "grid_svc.fit(X_train, y_train)\n",
        "\n",
        "# SVC best estimator\n",
        "svc = grid_svc.best_estimator_\n",
        "\n",
        "# DecisionTree Classifier\n",
        "tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)),\n",
        "              \"min_samples_leaf\": list(range(5,7,1))}\n",
        "grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\n",
        "grid_tree.fit(X_train, y_train)\n",
        "\n",
        "# tree best estimator\n",
        "tree_clf = grid_tree.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "7f327bcd-335f-4e49-af07-fc4214dbcbdc",
        "_uuid": "1b2108bf377b924ed8a6efe580d9e162a132cd9e",
        "trusted": true,
        "id": "Vod9oxifwLSf"
      },
      "cell_type": "code",
      "source": [
        "# Overfitting Case\n",
        "\n",
        "log_reg_score = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
        "print('Logistic Regression Cross Validation Score: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\n",
        "\n",
        "\n",
        "knears_score = cross_val_score(knears_neighbors, X_train, y_train, cv=5)\n",
        "print('Knears Neighbors Cross Validation Score', round(knears_score.mean() * 100, 2).astype(str) + '%')\n",
        "\n",
        "svc_score = cross_val_score(svc, X_train, y_train, cv=5)\n",
        "print('Support Vector Classifier Cross Validation Score', round(svc_score.mean() * 100, 2).astype(str) + '%')\n",
        "\n",
        "tree_score = cross_val_score(tree_clf, X_train, y_train, cv=5)\n",
        "print('DecisionTree Classifier Cross Validation Score', round(tree_score.mean() * 100, 2).astype(str) + '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "38e430ef-0160-47a1-9b6f-11ff62c5ecc0",
        "_uuid": "eeb5736b279bb8fa3804689a175394f216ec4f72",
        "trusted": true,
        "id": "xuqauPGuwLSf"
      },
      "cell_type": "code",
      "source": [
        "# We will undersample during cross validating\n",
        "undersample_X = df.drop('Class', axis=1)\n",
        "undersample_y = df['Class']\n",
        "\n",
        "for train_index, test_index in sss.split(undersample_X, undersample_y):\n",
        "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
        "    undersample_Xtrain, undersample_Xtest = undersample_X.iloc[train_index], undersample_X.iloc[test_index]\n",
        "    undersample_ytrain, undersample_ytest = undersample_y.iloc[train_index], undersample_y.iloc[test_index]\n",
        "\n",
        "undersample_Xtrain = undersample_Xtrain.values\n",
        "undersample_Xtest = undersample_Xtest.values\n",
        "undersample_ytrain = undersample_ytrain.values\n",
        "undersample_ytest = undersample_ytest.values\n",
        "\n",
        "undersample_accuracy = []\n",
        "undersample_precision = []\n",
        "undersample_recall = []\n",
        "undersample_f1 = []\n",
        "undersample_auc = []\n",
        "\n",
        "# Implementing NearMiss Technique\n",
        "# Distribution of NearMiss (Just to see how it distributes the labels we won't use these variables)\n",
        "X_nearmiss, y_nearmiss = NearMiss().fit_sample(undersample_X.values, undersample_y.values)\n",
        "print('NearMiss Label Distribution: {}'.format(Counter(y_nearmiss)))\n",
        "# Cross Validating the right way\n",
        "\n",
        "for train, test in sss.split(undersample_Xtrain, undersample_ytrain):\n",
        "    undersample_pipeline = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), log_reg) # SMOTE happens during Cross Validation not before..\n",
        "    undersample_model = undersample_pipeline.fit(undersample_Xtrain[train], undersample_ytrain[train])\n",
        "    undersample_prediction = undersample_model.predict(undersample_Xtrain[test])\n",
        "\n",
        "    undersample_accuracy.append(undersample_pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
        "    undersample_precision.append(precision_score(original_ytrain[test], undersample_prediction))\n",
        "    undersample_recall.append(recall_score(original_ytrain[test], undersample_prediction))\n",
        "    undersample_f1.append(f1_score(original_ytrain[test], undersample_prediction))\n",
        "    undersample_auc.append(roc_auc_score(original_ytrain[test], undersample_prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "bb72803c-3ea3-40cd-8ac3-399540ab7f5a",
        "_uuid": "a12fb2f7e104931bb78e1bd6cfc5a516c970708b",
        "trusted": true,
        "id": "DBHq9CsjwLSg"
      },
      "cell_type": "code",
      "source": [
        "# Let's Plot LogisticRegression Learning Curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "def plot_learning_curve(estimator1, estimator2, estimator3, estimator4, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(20,14), sharey=True)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    # First Estimator\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator1, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"#ff9124\")\n",
        "    ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n",
        "    ax1.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n",
        "             label=\"Training score\")\n",
        "    ax1.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n",
        "             label=\"Cross-validation score\")\n",
        "    ax1.set_title(\"Logistic Regression Learning Curve\", fontsize=14)\n",
        "    ax1.set_xlabel('Training size (m)')\n",
        "    ax1.set_ylabel('Score')\n",
        "    ax1.grid(True)\n",
        "    ax1.legend(loc=\"best\")\n",
        "\n",
        "    # Second Estimator\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator2, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    ax2.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"#ff9124\")\n",
        "    ax2.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n",
        "    ax2.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n",
        "             label=\"Training score\")\n",
        "    ax2.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n",
        "             label=\"Cross-validation score\")\n",
        "    ax2.set_title(\"Knears Neighbors Learning Curve\", fontsize=14)\n",
        "    ax2.set_xlabel('Training size (m)')\n",
        "    ax2.set_ylabel('Score')\n",
        "    ax2.grid(True)\n",
        "    ax2.legend(loc=\"best\")\n",
        "\n",
        "    # Third Estimator\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator3, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    ax3.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"#ff9124\")\n",
        "    ax3.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n",
        "    ax3.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n",
        "             label=\"Training score\")\n",
        "    ax3.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n",
        "             label=\"Cross-validation score\")\n",
        "    ax3.set_title(\"Support Vector Classifier \\n Learning Curve\", fontsize=14)\n",
        "    ax3.set_xlabel('Training size (m)')\n",
        "    ax3.set_ylabel('Score')\n",
        "    ax3.grid(True)\n",
        "    ax3.legend(loc=\"best\")\n",
        "\n",
        "    # Fourth Estimator\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator4, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    ax4.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"#ff9124\")\n",
        "    ax4.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n",
        "    ax4.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n",
        "             label=\"Training score\")\n",
        "    ax4.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n",
        "             label=\"Cross-validation score\")\n",
        "    ax4.set_title(\"Decision Tree Classifier \\n Learning Curve\", fontsize=14)\n",
        "    ax4.set_xlabel('Training size (m)')\n",
        "    ax4.set_ylabel('Score')\n",
        "    ax4.grid(True)\n",
        "    ax4.legend(loc=\"best\")\n",
        "    return plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "5b8302aa-0207-455f-8c1a-78ff3e9b5141",
        "_uuid": "15b262baa0c61c288a5453031b4d7f80f5a7a5ab",
        "trusted": true,
        "id": "F1hGxxe8wLSg"
      },
      "cell_type": "code",
      "source": [
        "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
        "plot_learning_curve(log_reg, knears_neighbors, svc, tree_clf, X_train, y_train, (0.87, 1.01), cv=cv, n_jobs=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "780e485a-ea64-48a0-ad97-a7516b047f32",
        "_uuid": "fdd59bf2c7a8e61cfb401142570643e8a29cf86b",
        "trusted": true,
        "id": "Rxe6Xe5XwLSg"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "# Create a DataFrame with all the scores and the classifiers names.\n",
        "\n",
        "log_reg_pred = cross_val_predict(log_reg, X_train, y_train, cv=5,\n",
        "                             method=\"decision_function\")\n",
        "\n",
        "knears_pred = cross_val_predict(knears_neighbors, X_train, y_train, cv=5)\n",
        "\n",
        "svc_pred = cross_val_predict(svc, X_train, y_train, cv=5,\n",
        "                             method=\"decision_function\")\n",
        "\n",
        "tree_pred = cross_val_predict(tree_clf, X_train, y_train, cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "57c211c6-e88f-4634-b321-4949df08815d",
        "_uuid": "cb2e4715e91e36f2029ef2a5c241991ff162cd9f",
        "trusted": true,
        "id": "yx_YbfzTwLSg"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print('Logistic Regression: ', roc_auc_score(y_train, log_reg_pred))\n",
        "print('KNears Neighbors: ', roc_auc_score(y_train, knears_pred))\n",
        "print('Support Vector Classifier: ', roc_auc_score(y_train, svc_pred))\n",
        "print('Decision Tree Classifier: ', roc_auc_score(y_train, tree_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "89b0b9b6-ef82-4b69-9517-e89a79696dbb",
        "_uuid": "9d57aad23f3f72f3c45bf80b089a65acbce2a9ab",
        "trusted": true,
        "id": "GBMlsP4lwLSg"
      },
      "cell_type": "code",
      "source": [
        "log_fpr, log_tpr, log_thresold = roc_curve(y_train, log_reg_pred)\n",
        "knear_fpr, knear_tpr, knear_threshold = roc_curve(y_train, knears_pred)\n",
        "svc_fpr, svc_tpr, svc_threshold = roc_curve(y_train, svc_pred)\n",
        "tree_fpr, tree_tpr, tree_threshold = roc_curve(y_train, tree_pred)\n",
        "\n",
        "\n",
        "def graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr):\n",
        "    plt.figure(figsize=(16,8))\n",
        "    plt.title('ROC Curve \\n Top 4 Classifiers', fontsize=18)\n",
        "    plt.plot(log_fpr, log_tpr, label='Logistic Regression Classifier Score: {:.4f}'.format(roc_auc_score(y_train, log_reg_pred)))\n",
        "    plt.plot(knear_fpr, knear_tpr, label='KNears Neighbors Classifier Score: {:.4f}'.format(roc_auc_score(y_train, knears_pred)))\n",
        "    plt.plot(svc_fpr, svc_tpr, label='Support Vector Classifier Score: {:.4f}'.format(roc_auc_score(y_train, svc_pred)))\n",
        "    plt.plot(tree_fpr, tree_tpr, label='Decision Tree Classifier Score: {:.4f}'.format(roc_auc_score(y_train, tree_pred)))\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.axis([-0.01, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate', fontsize=16)\n",
        "    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n",
        "                arrowprops=dict(facecolor='#6E726D', shrink=0.05),\n",
        "                )\n",
        "    plt.legend()\n",
        "\n",
        "graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f56e6936-314c-42d4-8ea2-0cb2386ad382",
        "_uuid": "d6e62d64e9d9aa70223576a1df91a008aa6c2664",
        "id": "gcCMslGqwLSg"
      },
      "cell_type": "markdown",
      "source": [
        "## A Deeper Look into LogisticRegression:\n"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "b4eaea18-ec79-4cb2-9a92-8d70a7f593bf",
        "_uuid": "0daaa7137ab61d6fd88e5fcc0849acc94c693df0",
        "trusted": true,
        "id": "_O_lIpiywLSg"
      },
      "cell_type": "code",
      "source": [
        "def logistic_roc_curve(log_fpr, log_tpr):\n",
        "    plt.figure(figsize=(12,8))\n",
        "    plt.title('Logistic Regression ROC Curve', fontsize=16)\n",
        "    plt.plot(log_fpr, log_tpr, 'b-', linewidth=2)\n",
        "    plt.plot([0, 1], [0, 1], 'r--')\n",
        "    plt.xlabel('False Positive Rate', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate', fontsize=16)\n",
        "    plt.axis([-0.01,1,0,1])\n",
        "\n",
        "\n",
        "logistic_roc_curve(log_fpr, log_tpr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d59c7621-5adb-4339-9a04-54630f679665",
        "_uuid": "f6d54ac036fa499104d269dd52d704c71629c1b0",
        "trusted": true,
        "id": "fMevu0pWwLSg"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, threshold = precision_recall_curve(y_train, log_reg_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "06d9e8b8-3ba5-4c1e-8480-af5a8e04f851",
        "_uuid": "b19df81d0a5178a260d7518f9cca804646839c01",
        "trusted": true,
        "id": "hb4kM1muwLSg"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
        "y_pred = log_reg.predict(X_train)\n",
        "\n",
        "# Overfitting Case\n",
        "print('---' * 45)\n",
        "print('Overfitting: \\n')\n",
        "print('Recall Score: {:.2f}'.format(recall_score(y_train, y_pred)))\n",
        "print('Precision Score: {:.2f}'.format(precision_score(y_train, y_pred)))\n",
        "print('F1 Score: {:.2f}'.format(f1_score(y_train, y_pred)))\n",
        "print('Accuracy Score: {:.2f}'.format(accuracy_score(y_train, y_pred)))\n",
        "print('---' * 45)\n",
        "\n",
        "# How it should look like\n",
        "print('---' * 45)\n",
        "print('How it should be:\\n')\n",
        "print(\"Accuracy Score: {:.2f}\".format(np.mean(undersample_accuracy)))\n",
        "print(\"Precision Score: {:.2f}\".format(np.mean(undersample_precision)))\n",
        "print(\"Recall Score: {:.2f}\".format(np.mean(undersample_recall)))\n",
        "print(\"F1 Score: {:.2f}\".format(np.mean(undersample_f1)))\n",
        "print('---' * 45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "89d88863-536f-4eea-a0cd-d2c77f407dd6",
        "_uuid": "f041ab92c183d2aa29569fc048ee6af4e6ee81f0",
        "trusted": true,
        "id": "oVQs6oXKwLSg"
      },
      "cell_type": "code",
      "source": [
        "undersample_y_score = log_reg.decision_function(original_Xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "3f54604f-396c-421e-ae93-305ad0103591",
        "_uuid": "c501d9226855a510a136bbf06794c702497e5b28",
        "trusted": true,
        "id": "OesvHOqLwLSg"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "undersample_average_precision = average_precision_score(original_ytest, undersample_y_score)\n",
        "\n",
        "print('Average precision-recall score: {0:0.2f}'.format(\n",
        "      undersample_average_precision))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "2442a51e-0263-48a3-99f9-06f47bdc04f1",
        "_uuid": "2edd5461ff5253f12955ac02106c323f7aabe49f",
        "trusted": true,
        "id": "LCl8-geqwLSg"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(original_ytest, undersample_y_score)\n",
        "\n",
        "plt.step(recall, precision, color='#004a93', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
        "                 color='#48a6ff')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('UnderSampling Precision-Recall curve: \\n Average Precision-Recall Score ={0:0.2f}'.format(\n",
        "          undersample_average_precision), fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "cc175ddc-ddd7-4087-ae1f-dd6fac664d58",
        "_uuid": "96f8d3f4160d65f12af4c7106739c4ad46d1e76b",
        "trusted": true,
        "id": "7WkZtIUtwLSg"
      },
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "\n",
        "\n",
        "print('Length of X (train): {} | Length of y (train): {}'.format(len(original_Xtrain), len(original_ytrain)))\n",
        "print('Length of X (test): {} | Length of y (test): {}'.format(len(original_Xtest), len(original_ytest)))\n",
        "\n",
        "# List to append the score and then find the average\n",
        "accuracy_lst = []\n",
        "precision_lst = []\n",
        "recall_lst = []\n",
        "f1_lst = []\n",
        "auc_lst = []\n",
        "\n",
        "# Classifier with optimal parameters\n",
        "# log_reg_sm = grid_log_reg.best_estimator_\n",
        "log_reg_sm = LogisticRegression()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "rand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)\n",
        "\n",
        "\n",
        "# Implementing SMOTE Technique\n",
        "# Cross Validating the right way\n",
        "# Parameters\n",
        "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
        "for train, test in sss.split(original_Xtrain, original_ytrain):\n",
        "    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_log_reg) # SMOTE happens during Cross Validation not before..\n",
        "    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n",
        "    best_est = rand_log_reg.best_estimator_\n",
        "    prediction = best_est.predict(original_Xtrain[test])\n",
        "\n",
        "    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
        "    precision_lst.append(precision_score(original_ytrain[test], prediction))\n",
        "    recall_lst.append(recall_score(original_ytrain[test], prediction))\n",
        "    f1_lst.append(f1_score(original_ytrain[test], prediction))\n",
        "    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n",
        "\n",
        "print('---' * 45)\n",
        "print('')\n",
        "print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n",
        "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
        "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
        "print(\"f1: {}\".format(np.mean(f1_lst)))\n",
        "print('---' * 45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "41dd6215-2927-4de3-999a-724272aea2b6",
        "_uuid": "d109652d1e170d0f9938d64f29aa33d93c941cdc",
        "trusted": true,
        "id": "ajgq3v5SwLSg"
      },
      "cell_type": "code",
      "source": [
        "labels = ['No Fraud', 'Fraud']\n",
        "smote_prediction = best_est.predict(original_Xtest)\n",
        "print(classification_report(original_ytest, smote_prediction, target_names=labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "f0e671f7-7ed1-4188-b9bf-e509f050b134",
        "_uuid": "a8dcc4bba95aed7fbc8b9e39ceeeec6902d1865c",
        "trusted": true,
        "id": "zZ03ihawwLSg"
      },
      "cell_type": "code",
      "source": [
        "y_score = best_est.decision_function(original_Xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "77bed8fa-1117-4bc0-a740-bd1bd97012a4",
        "_uuid": "f9213b24dd2fb3eb04f9b59c3b715dcb167664b5",
        "trusted": true,
        "id": "2Z79u2eCwLSg"
      },
      "cell_type": "code",
      "source": [
        "average_precision = average_precision_score(original_ytest, y_score)\n",
        "\n",
        "print('Average precision-recall score: {0:0.2f}'.format(\n",
        "      average_precision))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "54e926f4-2a5d-4bb1-b74c-8cd79da7b6e5",
        "_uuid": "7be0445ac80df7ca252ec350b026d6275669aea6",
        "trusted": true,
        "id": "DFvYVa2KwLSg"
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(original_ytest, y_score)\n",
        "\n",
        "plt.step(recall, precision, color='r', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
        "                 color='#F59B00')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title('OverSampling Precision-Recall curve: \\n Average Precision-Recall Score ={0:0.2f}'.format(\n",
        "          average_precision), fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "d5c6fe5b-f086-4151-aba5-3c758677be0f",
        "_uuid": "787ec6bb25c3dc379c12a57619f5cc3e41afa42e",
        "trusted": true,
        "id": "UUKQmSXAwLSh"
      },
      "cell_type": "code",
      "source": [
        "# SMOTE Technique (OverSampling) After splitting and Cross Validating\n",
        "sm = SMOTE(ratio='minority', random_state=42)\n",
        "# Xsm_train, ysm_train = sm.fit_sample(X_train, y_train)\n",
        "\n",
        "\n",
        "# This will be the data were we are going to\n",
        "Xsm_train, ysm_train = sm.fit_sample(original_Xtrain, original_ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "7af62152-e7e3-45c8-9a56-69467ede59a6",
        "_uuid": "a25f7cc327bbaeae985cb0d2f9a0c8e2c2009aa3",
        "trusted": true,
        "id": "jktGQCdDwLSh"
      },
      "cell_type": "code",
      "source": [
        "# We Improve the score by 2% points approximately\n",
        "# Implement GridSearchCV and the other models.\n",
        "\n",
        "# Logistic Regression\n",
        "t0 = time.time()\n",
        "log_reg_sm = grid_log_reg.best_estimator_\n",
        "log_reg_sm.fit(Xsm_train, ysm_train)\n",
        "t1 = time.time()\n",
        "print(\"Fitting oversample data took :{} sec\".format(t1 - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a250e819-cdd4-43f5-b0a4-eb8f232199a0",
        "_uuid": "feb07b601c9ec79be1fe96cbbadf4ac838f7f7a8",
        "id": "euDTj-eYwLSh"
      },
      "cell_type": "markdown",
      "source": [
        "# Test Data with Logistic Regression:\n"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "13a7d31c-2586-4946-aaa3-60090cd5680b",
        "_uuid": "d0e37500506d1b942431ac5bfabedcfea30275ce",
        "trusted": true,
        "id": "mQbf107iwLSh"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Logistic Regression fitted using SMOTE technique\n",
        "y_pred_log_reg = log_reg_sm.predict(X_test)\n",
        "\n",
        "# Other models fitted with UnderSampling\n",
        "y_pred_knear = knears_neighbors.predict(X_test)\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "y_pred_tree = tree_clf.predict(X_test)\n",
        "\n",
        "\n",
        "log_reg_cf = confusion_matrix(y_test, y_pred_log_reg)\n",
        "kneighbors_cf = confusion_matrix(y_test, y_pred_knear)\n",
        "svc_cf = confusion_matrix(y_test, y_pred_svc)\n",
        "tree_cf = confusion_matrix(y_test, y_pred_tree)\n",
        "\n",
        "fig, ax = plt.subplots(2, 2,figsize=(22,12))\n",
        "\n",
        "\n",
        "sns.heatmap(log_reg_cf, ax=ax[0][0], annot=True, cmap=plt.cm.copper)\n",
        "ax[0, 0].set_title(\"Logistic Regression \\n Confusion Matrix\", fontsize=14)\n",
        "ax[0, 0].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
        "ax[0, 0].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
        "\n",
        "sns.heatmap(kneighbors_cf, ax=ax[0][1], annot=True, cmap=plt.cm.copper)\n",
        "ax[0][1].set_title(\"KNearsNeighbors \\n Confusion Matrix\", fontsize=14)\n",
        "ax[0][1].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
        "ax[0][1].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
        "\n",
        "sns.heatmap(svc_cf, ax=ax[1][0], annot=True, cmap=plt.cm.copper)\n",
        "ax[1][0].set_title(\"Suppor Vector Classifier \\n Confusion Matrix\", fontsize=14)\n",
        "ax[1][0].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
        "ax[1][0].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
        "\n",
        "sns.heatmap(tree_cf, ax=ax[1][1], annot=True, cmap=plt.cm.copper)\n",
        "ax[1][1].set_title(\"DecisionTree Classifier \\n Confusion Matrix\", fontsize=14)\n",
        "ax[1][1].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
        "ax[1][1].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "bd4529fd-f38a-4dd1-8b63-467a15a2167d",
        "_uuid": "1380d639d3b9087ec767ed6db391fc4b8c01e765",
        "trusted": true,
        "id": "bEe0XyNtwLSh"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "print('Logistic Regression:')\n",
        "print(classification_report(y_test, y_pred_log_reg))\n",
        "\n",
        "print('KNears Neighbors:')\n",
        "print(classification_report(y_test, y_pred_knear))\n",
        "\n",
        "print('Support Vector Classifier:')\n",
        "print(classification_report(y_test, y_pred_svc))\n",
        "\n",
        "print('Support Vector Classifier:')\n",
        "print(classification_report(y_test, y_pred_tree))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "9103c5ed-df9d-4441-91dc-1104a51f06ff",
        "_uuid": "49c94105ad280d1ca16271daf7f9395041016c5c",
        "trusted": true,
        "id": "RLzP1VavwLSh"
      },
      "cell_type": "code",
      "source": [
        "# Final Score in the test set of logistic regression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Logistic Regression with Under-Sampling\n",
        "y_pred = log_reg.predict(X_test)\n",
        "undersample_score = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Logistic Regression with SMOTE Technique (Better accuracy with SMOTE t)\n",
        "y_pred_sm = best_est.predict(original_Xtest)\n",
        "oversample_score = accuracy_score(original_ytest, y_pred_sm)\n",
        "\n",
        "\n",
        "d = {'Technique': ['Random UnderSampling', 'Oversampling (SMOTE)'], 'Score': [undersample_score, oversample_score]}\n",
        "final_df = pd.DataFrame(data=d)\n",
        "\n",
        "# Move column\n",
        "score = final_df['Score']\n",
        "final_df.drop('Score', axis=1, inplace=True)\n",
        "final_df.insert(1, 'Score', score)\n",
        "\n",
        "# Note how high is accuracy score it can be misleading!\n",
        "final_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5ec3ca7c-fae2-4e0a-991b-bb689a8c4456",
        "_uuid": "d709eac19181e9b7026e2f9e9f780a207bc8c19a",
        "id": "yVc1yKAkwLSh"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Networks Testing Random UnderSampling Data vs OverSampling (SMOTE):\n"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "e774e22e-8ce0-4c2e-99fa-9f3c6a915b6d",
        "_uuid": "35be99c61da4054c952e1955a5e809d003966975",
        "trusted": true,
        "id": "e9fii9FowLSh"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "\n",
        "n_inputs = X_train.shape[1]\n",
        "\n",
        "undersample_model = Sequential([\n",
        "    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "c249283c-f4d9-43f4-a859-ccd5a7661cf7",
        "_uuid": "ccdae6b84326551e1ff5199c44f7d53ccd3179d9",
        "trusted": true,
        "id": "dEuDvk3twLSh"
      },
      "cell_type": "code",
      "source": [
        "undersample_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "6327357a-b8ca-4aa4-8764-48673b2d6c9d",
        "_uuid": "e2ec864b9ef6f530df28688a703bcc8f2243baa1",
        "trusted": true,
        "id": "50Iug5cTwLSh"
      },
      "cell_type": "code",
      "source": [
        "undersample_model.compile(Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "0067f625-d734-4c15-9526-6efb1c47dc2c",
        "_uuid": "98a36722723d4f7285eb9de158b12be9694a603f",
        "trusted": true,
        "id": "QqaSmVOawLSh"
      },
      "cell_type": "code",
      "source": [
        "undersample_model.fit(X_train, y_train, validation_split=0.2, batch_size=25, epochs=20, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "9a30cd49-23c3-4417-8ce1-b6e82890481c",
        "_uuid": "e82f40ef343b53b71d6fcfa317e872278db27114",
        "trusted": true,
        "id": "gyv3UaZgwLSh"
      },
      "cell_type": "code",
      "source": [
        "undersample_predictions = undersample_model.predict(original_Xtest, batch_size=200, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "a47a91a0-2cf3-436f-a1cd-bb207ba94997",
        "_uuid": "028270a5b2ba0e4c85100f287fec64343ad900ea",
        "trusted": true,
        "id": "-5szjHgpwLSh"
      },
      "cell_type": "code",
      "source": [
        "undersample_fraud_predictions = undersample_model.predict_classes(original_Xtest, batch_size=200, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "44216511-5fa7-404f-9b40-2c72f30c1ca7",
        "_uuid": "b0681d10d7f3e68a6b91864670b7aa04cacd362f",
        "trusted": true,
        "id": "rnNzLpclwLSh"
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "# Create a confusion matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "ee16d514-2134-4cfd-b4d8-1ddb183960f0",
        "_uuid": "003c84c96d49bebdb5f09970102d89e3db5ff2f1",
        "trusted": true,
        "id": "nkRB8rMHwLSh"
      },
      "cell_type": "code",
      "source": [
        "undersample_cm = confusion_matrix(original_ytest, undersample_fraud_predictions)\n",
        "actual_cm = confusion_matrix(original_ytest, original_ytest)\n",
        "labels = ['No Fraud', 'Fraud']\n",
        "\n",
        "fig = plt.figure(figsize=(16,8))\n",
        "\n",
        "fig.add_subplot(221)\n",
        "plot_confusion_matrix(undersample_cm, labels, title=\"Random UnderSample \\n Confusion Matrix\", cmap=plt.cm.Reds)\n",
        "\n",
        "fig.add_subplot(222)\n",
        "plot_confusion_matrix(actual_cm, labels, title=\"Confusion Matrix \\n (with 100% accuracy)\", cmap=plt.cm.Greens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9d7cd385-9270-426e-b537-c80501dce889",
        "_uuid": "be2b0e76445ecb745b6e49e69993dd1de7839eb4",
        "id": "RNlOqqIzwLSh"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras || OverSampling (SMOTE):\n"
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "e7c29164-751a-4ccd-b517-527debf38fdf",
        "_uuid": "7130856ed8a6f87fe86b72c5142ff27ccf4eef1a",
        "trusted": true,
        "id": "bsBNmxL5wLSh"
      },
      "cell_type": "code",
      "source": [
        "n_inputs = Xsm_train.shape[1]\n",
        "\n",
        "oversample_model = Sequential([\n",
        "    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "25beccc6-fe0b-4c85-a439-81aaf5cdc019",
        "_uuid": "937a0a57f3dae8172fb6c88b60944257e8198ae7",
        "trusted": true,
        "id": "ptJwsYqvwLSh"
      },
      "cell_type": "code",
      "source": [
        "oversample_model.compile(Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "888c3acd-3d8d-4f1b-b68a-bef304feca14",
        "_uuid": "5ddbf33763fb33393d7969fdbd7338aa8e708c43",
        "trusted": true,
        "id": "HGlnNr5NwLSh"
      },
      "cell_type": "code",
      "source": [
        "oversample_model.fit(Xsm_train, ysm_train, validation_split=0.2, batch_size=300, epochs=20, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "09628790-3d4b-4516-b355-4177e5ad9329",
        "_uuid": "222a3f8e7614c4e0241e0f0c85b0ecd45fd3cca6",
        "trusted": true,
        "id": "ijIo5-mvwLSi"
      },
      "cell_type": "code",
      "source": [
        "oversample_predictions = oversample_model.predict(original_Xtest, batch_size=200, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "374217c9-a4b7-4691-918b-6a91bb1c02e3",
        "_uuid": "9ede2c436251f560615087202cff031936f3a6e5",
        "trusted": true,
        "id": "YdvTsit5wLSi"
      },
      "cell_type": "code",
      "source": [
        "oversample_fraud_predictions = oversample_model.predict_classes(original_Xtest, batch_size=200, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "9a58d39f-9149-4279-bce3-fc8372e55f93",
        "_uuid": "a18452b7051e4905f32b27940f006d0bc4bc2d5e",
        "trusted": true,
        "id": "YmX6OjWcwLSi"
      },
      "cell_type": "code",
      "source": [
        "oversample_smote = confusion_matrix(original_ytest, oversample_fraud_predictions)\n",
        "actual_cm = confusion_matrix(original_ytest, original_ytest)\n",
        "labels = ['No Fraud', 'Fraud']\n",
        "\n",
        "fig = plt.figure(figsize=(16,8))\n",
        "\n",
        "fig.add_subplot(221)\n",
        "plot_confusion_matrix(oversample_smote, labels, title=\"OverSample (SMOTE) \\n Confusion Matrix\", cmap=plt.cm.Oranges)\n",
        "\n",
        "fig.add_subplot(222)\n",
        "plot_confusion_matrix(actual_cm, labels, title=\"Confusion Matrix \\n (with 100% accuracy)\", cmap=plt.cm.Greens)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}